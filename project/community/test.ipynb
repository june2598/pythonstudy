{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('total_community_contents_1m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종목코드 자릿수 손실 : 6자리 채우기\n",
    "df['종목'] = df['종목'].apply(\n",
    "    lambda x: f\"{x.zfill(6)}\" if len(x) < 6 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>닉네임</th>\n",
       "      <th>날짜</th>\n",
       "      <th>내용</th>\n",
       "      <th>종목</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GROK</td>\n",
       "      <td>2025-01-11T22:59:18+09:00</td>\n",
       "      <td>- 디자인 변화: S25 울트라는 기존의 각진 디자인에서 둥근 모서리로 변경되었으며...</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>공감아</td>\n",
       "      <td>2025-01-11T22:47:22+09:00</td>\n",
       "      <td>7만원 8만원에 물려있는게 대부분이라 7만원까지 혹여 올라도 물려있던분들은 원금 회...</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>곰돌이와콩이</td>\n",
       "      <td>2025-01-11T22:41:04+09:00</td>\n",
       "      <td>분할매수하기에 좋은 타점이지만.. 얘는 너무느리고 오래걸린다 얘를살바에 살게 너무많...</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>김브래</td>\n",
       "      <td>2025-01-11T21:31:55+09:00</td>\n",
       "      <td>존버하면 오르겠죠?</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김보리씨</td>\n",
       "      <td>2025-01-11T21:07:54+09:00</td>\n",
       "      <td>오를 겁니다. 제가 오늘 열심히 일하고 퇴근했습니다.</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>추팝츄스</td>\n",
       "      <td>2025-01-11T17:58:08+09:00</td>\n",
       "      <td>믿을거 하나없고 과거가 어떤지도 모르는 사람한테 투자한 사람이야 이렇게 믿을을주는 ...</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>복권1등지방</td>\n",
       "      <td>2025-01-11T17:43:07+09:00</td>\n",
       "      <td>정치에 관심이 없는데 이제부터 공부하려고 하는데 윤석열 대통령님이 틴핵되어야 선진국...</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>삼전35만원</td>\n",
       "      <td>2025-01-11T17:26:18+09:00</td>\n",
       "      <td>https://youtu.be/f-8vau3NfMY?si=-dLlQD9Ph5OU1Wes</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>분할매수매도장인</td>\n",
       "      <td>2025-01-11T16:46:27+09:00</td>\n",
       "      <td>요즘 왜 미세먼지가 없냐?? 중국이 망하는 중이냐? 아니면 친환경으로 바꾼거냐??</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>추팝츄스</td>\n",
       "      <td>2025-01-11T16:35:12+09:00</td>\n",
       "      <td>뭔가 보여주고 싶지 않아? 보란듯이 한번 바뀌고 싶지 않아? 그걸 한 번 보여줘!\\...</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        닉네임                         날짜  \\\n",
       "0      GROK  2025-01-11T22:59:18+09:00   \n",
       "1       공감아  2025-01-11T22:47:22+09:00   \n",
       "2    곰돌이와콩이  2025-01-11T22:41:04+09:00   \n",
       "3       김브래  2025-01-11T21:31:55+09:00   \n",
       "4      김보리씨  2025-01-11T21:07:54+09:00   \n",
       "5      추팝츄스  2025-01-11T17:58:08+09:00   \n",
       "6    복권1등지방  2025-01-11T17:43:07+09:00   \n",
       "7    삼전35만원  2025-01-11T17:26:18+09:00   \n",
       "8  분할매수매도장인  2025-01-11T16:46:27+09:00   \n",
       "9      추팝츄스  2025-01-11T16:35:12+09:00   \n",
       "\n",
       "                                                  내용      종목  \n",
       "0  - 디자인 변화: S25 울트라는 기존의 각진 디자인에서 둥근 모서리로 변경되었으며...  005930  \n",
       "1  7만원 8만원에 물려있는게 대부분이라 7만원까지 혹여 올라도 물려있던분들은 원금 회...  005930  \n",
       "2  분할매수하기에 좋은 타점이지만.. 얘는 너무느리고 오래걸린다 얘를살바에 살게 너무많...  005930  \n",
       "3                                         존버하면 오르겠죠?  005930  \n",
       "4                      오를 겁니다. 제가 오늘 열심히 일하고 퇴근했습니다.  005930  \n",
       "5  믿을거 하나없고 과거가 어떤지도 모르는 사람한테 투자한 사람이야 이렇게 믿을을주는 ...  005930  \n",
       "6  정치에 관심이 없는데 이제부터 공부하려고 하는데 윤석열 대통령님이 틴핵되어야 선진국...  005930  \n",
       "7   https://youtu.be/f-8vau3NfMY?si=-dLlQD9Ph5OU1Wes  005930  \n",
       "8      요즘 왜 미세먼지가 없냐?? 중국이 망하는 중이냐? 아니면 친환경으로 바꾼거냐??  005930  \n",
       "9  뭔가 보여주고 싶지 않아? 보란듯이 한번 바뀌고 싶지 않아? 그걸 한 번 보여줘!\\...  005930  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87102 entries, 0 to 87101\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   닉네임     87102 non-null  object\n",
      " 1   날짜      87102 non-null  object\n",
      " 2   내용      87102 non-null  object\n",
      " 3   종목      87102 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "시장\n",
       "KOSPI            48471\n",
       "KOSDAQ           16636\n",
       "KOSDAQ GLOBAL     5468\n",
       "ETF               1937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['시장'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '시장'이 'KOSDAQ GLOBAL'인 경우 'KOSDAQ'으로 변경\n",
    "df.loc[df['시장'] == 'KOSDAQ GLOBAL', '시장'] = 'KOSDAQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "시장\n",
       "KOSPI     48471\n",
       "KOSDAQ    22104\n",
       "ETF        1937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['시장'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['종목'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = df.drop_duplicates(subset='종목')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_date = df['날짜'].max()\n",
    "earliest_date = df['날짜'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2025-01-12T20:40:39+09:00', '2024-12-12T00:04:12+09:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_date, earliest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "시장\n",
       "KOSPI     365\n",
       "KOSDAQ     99\n",
       "ETF        67\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df['시장'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언더 샘플링\n",
    "\n",
    "sample_data_positive = result2[result2['label'] == 1].sample(12916)\n",
    "sample_data_negative = result2[result2['label'] == 0].sample(12916)\n",
    "\n",
    "total_data = pd.concat([sample_data_positive,sample_data_negative])\n",
    "\n",
    "# 중복 내용 제거\n",
    "total_data = total_data.drop_duplicates(subset=['내용'])\n",
    "\n",
    "# 학습 데이터와, 테스트 데이터를 구분\n",
    "train_data, test_data = train_test_split(total_data, test_size=0.25, random_state=2025)\n",
    "\n",
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_data['내용'] = train_data['내용'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)\n",
    "train_data['내용'] = train_data['내용'].str.replace('^ +', \"\", regex=True) # white space 데이터를 empty value로 변경\n",
    "train_data['내용'].replace('', np.nan, inplace=True)\n",
    "\n",
    "test_data.drop_duplicates(subset = ['내용'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "test_data['내용'] = test_data['내용'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True) # 정규 표현식 수행\n",
    "test_data['내용'] = test_data['내용'].str.replace('^ +', \"\", regex=True) # 공백은 empty 값으로 변경\n",
    "test_data['내용'] = test_data['내용'].replace('', np.nan) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거\n",
    "\n",
    "stopwords = ['의','가','이','은','들','는',\n",
    "             '좀','잘','걍','과','도','를',\n",
    "             '으로','자','에','와','한','하다',\n",
    "             '을','있다','되다','보다','로','이다',\n",
    "             '요','일','안','것','주','다','년','속',\n",
    "             '합', '니', '딘','저', '두', '적','고',\n",
    "             '나'\n",
    "             ]\n",
    "\n",
    "X_train = []\n",
    "for sentence in tqdm(train_data['내용']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(stopwords_removed_sentence)\n",
    "\n",
    "\n",
    "X_test = []\n",
    "for sentence in tqdm(test_data['내용']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(stopwords_removed_sentence)\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# key,value : 단어, 빈도수\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 등장 빈도수 < threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "# 0번 패딩 토큰을 고려하여 + 1\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)\n",
    "\n",
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])\n",
    "\n",
    "# 빈 샘플들을 제거\n",
    "X_train = np.array(X_train, dtype=object)\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))\n",
    "  \n",
    "max_len = 100\n",
    "below_threshold_len(max_len, X_train)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=4, callbacks=[es, mc], batch_size=64, validation_split=0.2)\n",
    "\n",
    "loaded_model = load_model('best_model.keras')\n",
    "test_loss, test_acc= loaded_model.evaluate(X_test, y_test)\n",
    "print('\\n 테스트 손실 : %.4f' % test_loss)\n",
    "print('\\n 테스트 정확도: %.4f' % test_acc)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
