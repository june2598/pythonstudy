import pandas as pd
import numpy as np


# 모든 컬럼을 출력하도록 설정
pd.set_option('display.max_columns', None)  # None으로 설정하면 모든 컬럼 출력 default:20
# 모든 행을 출력하도록 설정
pd.set_option('display.max_rows', 10)  # None으로 설정하면 모든 행 출력 default:50
# 모든 열의 최대 너비를 설정
pd.set_option('display.max_colwidth', None) # None으로 설정하면 모든 내용을 출력 default:60


import seaborn as sns
import matplotlib.pyplot as plt
import koreanize_matplotlib
from wordcloud import WordCloud


# 정규표현식
import re


# 날짜는 파이썬 표준라이브러리 datetime 사용
import datetime


import matplotlib.font_manager as fm
# 원하는 폰트 경로 설정
font_path = "C:/Windows/Fonts/malgun.ttf" # 예시 경로
font_prop = fm.FontProperties(fname=font_path)

plt.rc('font', family=font_prop.get_name())


# 오늘 날짜 구하기
today = datetime.datetime.today()
print(today)
today = today.strftime('%Y-%m-%d')
today


df = pd.read_csv(f'../stock/news_preprocessed_{today}.csv')
df.head(1)





# K-means 군집화
from sklearn.cluster import KMeans


from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer


cvect = CountVectorizer()
cvect_dtm = cvect.fit_transform(df['제목_명사'])
cvect_dtm


tvect = TfidfVectorizer()
tvect_dtm = tvect.fit_transform(df['제목_명사'])
tvect_dtm


num_cluster = 7
kmeans = KMeans(n_clusters=num_cluster, n_init='auto', random_state=2025)
clusters = kmeans.fit(tvect_dtm).predict(tvect_dtm)                   # kmeans.labels_와 동일
clusters

# 0~6번 사이의 클러스터 내에 라벨링


kmeans.labels_


df_clustered = pd.DataFrame()
df_clustered['제목'] = df['제목'].copy()
df_clustered['제목_명사'] = df['제목_명사'].copy()
df_clustered['label'] = kmeans.labels_
df_clustered.sort_values(by='label')


df_clustered['label'].value_counts()


df_clustered.query('label ==3')





tvect_dtm.shape


# t-SNE (t-distributed Stochastic Neighbor Embedding)
from sklearn.manifold import TSNE


tsne = TSNE(n_components=2, perplexity=10, random_state=2025, init="random")
tsne_result = tsne.fit_transform(tvect_dtm)
tsne_result


df_tsne = pd.DataFrame(tsne_result, columns=['X','Y'])
df_tsne['제목'] = df['제목'].copy()
df_tsne['제목_명사'] = df['제목_명사'].copy()
df_tsne['label'] = kmeans.labels_
df_tsne


# 2차원 산점도로 군집 결과 시각화

sns.scatterplot(data=df_tsne, x='X', y='Y', hue='label',palette='Set1')


plt.text?


# 텍스트 정보 추가해서 시각화해보기
plt.figure(figsize=(20,30))
sns.scatterplot(data=df_tsne, x='X', y='Y', hue='label', palette='Set1')
for i in df_tsne.index:
    plt.text(x=df_tsne.loc[i,'X'], y=df_tsne.loc[i,'Y'], s=df_tsne.loc[i,'제목_명사'])


# kmeans.inertia_
# 클러스터 내의 데이터 포인트와 클러스터 중심 간의 거리의 제곱합
# kmeans.inertia_값이 낮을수록 클러스터가 더 밀집되었다는 것을 의미하며, 클러스터링의 품질이 높다고 볼 수 있습니다.
# kmeans.inertia_ 값을 사용하여 엘보우 (Elobw Method) 기법을 적용할 수 있습니다. 즉 극겹히 감소하는 저점을 찾아 최적의 클러스터 수를 결정할 수 있습니다.
kmeans.inertia_


from sklearn.metrics import silhouette_score
from tqdm import trange


# silhouette_score : 각 데이터 포인트가 얼마나 잘 클러스터링되어는지를 나타내는 지표
#                    값의 범위 -1 ~ 1 사이
# 1에 가까움 : 클러스터링이 잘 되었음을 의미, 다른 클러스터간의 거리가 멀다.
# 0 : 데이터 포인터가 클러스터링의 경계에 위치하고 있음을 의미
# -1에 가까움 : 클러스터링이 잘 수행되지 않았음을 의미
silhouette_score(tvect_dtm, kmeans.labels_)


# 엘보우 포인트:

# 그래프에서 '엘보우(팔꿈치)' 형태를 찾는 것이 중요합니다. 
# 엘보우 포인트는 관성값의 감소율이 급격히 줄어드는 지점으로, 이 지점에서 클러스터 수를 선택하는 것이 일반적입니다. 이 점을 기준으로 클러스터 수를 결정할 수 있습니다.


inertia = []
silhoutes = []
for n in trange(2,30) : 
    kmeans = KMeans(n_clusters=n, n_init='auto', random_state=2025)
    clusters = kmeans.fit(tvect_dtm)  
    inertia.append(kmeans.inertia_)
    silhoutes.append(silhouette_score(tvect_dtm, kmeans.labels_))


plt.figure(figsize=(15,4))
plt.plot(range(2,30), inertia)
plt.title('The Elbow Method')
plt.xlabel('number of cluster')
plt.ylabel('Within Sum of Square')
plt.show()
