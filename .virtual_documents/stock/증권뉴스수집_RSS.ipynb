import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import numpy as np


news_rss_url = {
    '매일경제': 'https://www.mk.co.kr/rss/50200011/',
    '한국경제': 'https://www.hankyung.com/feed/finance'
}


class Article :
    def __init__(self, *, media, datetime, title, content) :
        self.media = media
        self.datetime = datetime
        self.title = title
        self.content = content

    # def __repr__(self):
    #     return f"Article(media='{self.media}', datetime='{self.datetime}', title='{self.title}', content='{self.content}'"









def get_news_rss(media,url) :

    article_list = []
    title_list = []      # 기사 제목 목록
    link_list = []       # 기사 링크 목록
    news_data = []       # 기사 본문 목록
    news_datetime = []   # 기사 작성일시 목록

    headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'
    }
    news_rss = requests.get(url, headers=headers)
    news_rss_soup = BeautifulSoup(news_rss.content,'xml')

    # 기사 제목 수집
    title_list = news_rss_soup.select('item > title')
    title_list = [title.text for title in title_list]

    # 기사 상세링크 수집
    link_list = news_rss_soup.select('item > link')
    link_list = [link.text for link in link_list]

    # 기사 내용, 기사 작성일시 수집
    for link in link_list :
        news_res = requests.get(link, headers=headers)
        news_content_soup = BeautifulSoup(news_res.content, 'lxml')

        if media == '매일경제' :
            news_content = news_content_soup.select_one('.news_cnt_detail_wrap')
            news_data.append(news_content.text)
            news_datetime.append(news_content_soup.select_one('.time_area .registration dd').text)

        elif media == '한국경제' : 
            news_content = news_content_soup.select_one('#articletxt')
            if news_content:
                news_data.append(news_content.text)
                datetime_element = news_content_soup.select_one('.datetime > .item > .txt-date')
                news_datetime.append(datetime_element.text)
            else:
                print(link)
                continue
         
        # 기사 목록
    for item in zip(title_list, news_data, news_datetime) : 
        article = Article(media = media, title = item[0], content=item[1], datetime = item[2])
        article_list.append(article)
    return article_list



# 모든 언론사 기사 합치기

all_article_list=[]
for media,url in news_rss_url.items():
    print(media,url)
    list_data = get_news_rss(media, url)
    all_article_list.append(list_data)
print(len(all_article_list))


result = np.array(all_article_list).flatten().tolist()
print(len(result))
print(type(result))


data = {
    '언론사': [article.media for article in result ],
    '제목': [article.title for article in result ],
    '내용': [article.content for article in result ],
    '작성일시': [article.datetime for article in result ],    
}


df = pd.DataFrame(data)
df.head(3)


# 날짜는 파이썬 표준 라이브러리 datetime 사용
import datetime
# 오늘 날짜 가져오기
today = datetime.datetime.today()
today = today.strftime('%Y-%m-%d')
today


file_name = f'news_{today}.csv'
file_name


df.to_csv(file_name,index=False)



