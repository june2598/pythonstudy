# http 요청 응답, html 구문 분석
import requests
from bs4 import BeautifulSoup
import re


# 셀레니움 브라우저의 동작을 자동화하는 패키지
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By


# 데이터 분석 패키지
import pandas as pd


url = 'https://finance.naver.com/sise/sise_group.naver?type=upjong'


# # 브라우저 종료 방지 옵션
chrome_options = Options()
chrome_options.add_experimental_option('detach',True)

# # 웹 드라이버를 이용한 브라우저 제어
driver = webdriver.Chrome(options=chrome_options)

driver.implicitly_wait(1)


driver.get(url)


soup = BeautifulSoup(driver.page_source, 'html.parser')


soup.select_one('#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span').text


pattern = re.compile(r'100%')
pattern.findall(driver.page_source)


ele = driver.find_element(By.CSS_SELECTOR, '#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span')


ele.text


from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
wait = WebDriverWait(driver, 3)
element = wait.until(
EC.presence_of_element_located((By.CSS_SELECTOR,'#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span'))
)


driver.execute_script("return document.querySelector('#contentarea_left > table > tbody > tr:nth-child(4) > td.tc > div > div > span').textContent")



