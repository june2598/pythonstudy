import pandas as pd
# from math import log
import numpy as np


np.log(1000)


corpus = [
    '배우고 싶은 자연어',
    '배우고 싶은 딥러닝',
    '딥러닝 머신러닝 배우고 싶은 머신러닝',
    '자연어 처리 좋아요'
]


# set : 리스트에서 중복된 값 제거
vocab = list(set([w for doc in corpus for w in doc.split()]))
vocab.sort()


vocab


N = len(vocab)
N


# 문서 수
dc = len(corpus)

# 단어 빈도(term-frequency)
def tf(t, d):
    return d.count(t)

# inverse-문서 빈도
def idf(t):
    # 문서빈도 초기화
    df = 0
    for doc in corpus:
        # True면 1을 누적하고, False면 0을 누적
        df += t in doc

    # return np.log( dc / (df + 1) )
    return np.log( (dc + 1) / (df + 1) ) + 1    # 전체 문서수 / 단어가 등장하는 문서 수

# 단어빈도 * Inverse 문서빈도 => 가중치
def tfidf(t, d) :
    return tf(t,d) * idf(t)


result = []
for i in range(dc) :
    result.append([])
    d = corpus[i]
    for j in range(len(vocab)):
        t = vocab[j]
        result[-1].append(tf(t,d))

tf_ = pd.DataFrame(result, columns = vocab)
        


tf_


result = []
for j in range(len(vocab)) : 
    t = vocab[j]
    result.append(idf(t))

idf_ = pd.DataFrame(result, index=vocab, columns=['IDF'])
idf_


result = []
for i in range(dc) :
    result.append([])
    d = corpus[i]
    for j in range(len(vocab)):
        t = vocab[j]
        result[-1].append(tfidf(t,d))

tfidf_ = pd.DataFrame(result, columns = vocab)
tfidf_


from sklearn.feature_extraction.text import TfidfVectorizer


tfidfvect = TfidfVectorizer()
X = tfidfvect.fit_transform(corpus)
X


tfidfvect.vocabulary_


tfidfvect.idf_



