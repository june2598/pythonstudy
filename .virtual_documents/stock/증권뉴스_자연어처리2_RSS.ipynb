import pandas as pd
import numpy as np


# 시각화 패키지
import matplotlib.pyplot as plt
import seaborn as sns
import koreanize_matplotlib
from wordcloud import WordCloud


# 모든 컬럼,행을 출력하도록 설정
pd.set_option('display.max_columns', None) # None으로 설정하면 모든 컬럼 출력
pd.set_option('display.max_rows', 50) #None으로 설정하면 모든 행 출력

# 모든 열의 최대 너비를 설정
pd.set_option('display.max_colwidth', None) #None으로 설정하면 모든 내용을 출력


# 정규화
import re


# 날짜는 파이썬 표준 라이브러리 datetime 사용
import datetime
# 오늘 날짜 가져오기
today = datetime.datetime.today()
print(today)
today = today.strftime('%Y-%m-%d')
today


df = pd.read_csv(f'news_{today}.csv')
df.head(1)





corpus = df['제목']
corpus


from sklearn.feature_extraction.text import CountVectorizer


CountVectorizer?





# 공백을 중심으로 토큰화하고, 빈도수 확인
cvect = CountVectorizer(max_df=5,min_df=2, ngram_range=(1,2))





X = cvect.fit_transform(corpus)
X


# 단어사전 확인
# 단어사전은 {'단어' : 인덱스번호 }
cvect.vocabulary_


X.toarray()


cvect.get_feature_names_out()


cvect.get_feature_names_out().size


# n번 등장한 단어는 n, 아닌 단어는 0
tmp = pd.DataFrame(X.toarray(), columns = cvect.get_feature_names_out())


tmp.head(2)


tmp.sum().sort_values(ascending=False)


# 모델을 받아서 변환후 문서-어휘 행렬로 반환하는 함수

def display_transform_dtm(cvect, corpus) : 
    '''
    모델을 받아 변환하고 문서-어휘 행렬을 반환하는 함수
    '''

    X = cvect.fit_transform(corpus)
    dtm = X.toarray()
    df_dtm = pd.DataFrame(dtm, columns = cvect.get_feature_names_out()).style.background_gradient()
    return df_dtm



display_transform_dtm(cvect, corpus)


# ngram_range(2,3)
cvect = CountVectorizer(ngram_range=(2,3))
display_transform_dtm(cvect, corpus)





from sklearn.feature_extraction.text import TfidfVectorizer


tfidfvect = TfidfVectorizer()
X = tfidfvect.fit(corpus).transform(corpus)  # tfidfvect.fit_transform(corpus)와 동일
X


# 문서에 토큰이 더 많이 나타날수록 가중치는 더 커진다 TF
# 그러나 토큰이 여러문서에 많이 표시될수록 가중치는 감소 IDF
dtm = X.toarray()
dtm


display_transform_dtm(tfidfvect, corpus)


tfidfvect.idf_


vocab = tfidfvect.get_feature_names_out()
idf_dict = dict(zip(vocab, tfidfvect.idf_))
idf_dict


pd.Series(idf_dict).nlargest(30).to_frame().style.background_gradient()


pd.Series(idf_dict).nsmallest(30).to_frame().plot.barh()


tfidfvect = TfidfVectorizer(ngram_range=(3,4), max_df = 0.9, min_df = 1)
display_transform_dtm(tfidfvect, corpus)





df.head(1)


def display_word_cloud(str, max_words=30, width=1200,height=600) : 

    # r스트링 쓰는이유 : \ 를 특별한 의미로 해석하지말고 평범한 하나의 문자로 해석하게 하기위함
    font_path = r'C:\Windows\Fonts\malgun.ttf'
    stopwords = ['코스피','코스닥','종목','ETF','주식','주가','올해','내년','상장','시총','상승','하락','국내','해외','외국인','투자','서학','동학','소식에','기대감','기업','시장','목표가']
    word_cloud = WordCloud(font_path = font_path,
              width=width,
              height=height,
              stopwords=stopwords,
              background_color='white',
              min_word_length = 2,
              max_words = max_words,
              random_state=2024).generate(str)
    plt.imshow(word_cloud)
    plt.show()
    return word_cloud


corpus_content = df['내용']
corpus_content


# 공백을 중심으로 토큰화하고, 빈도수 확인
stop_words = ['fi'] 
cvect_content = CountVectorizer(max_df=5,min_df=2, ngram_range=(1,2),stop_words=stop_words)


cvect_content


X_content = cvect_content.fit_transform(corpus_content)


cvect_content.vocabulary_


 cvect_content_list = cvect_content.get_feature_names_out()


# 모델을 받아서 변환후 문서-어휘 행렬로 반환하는 함수

def display_transform_dtm(cvect, corpus) : 
    '''
    모델을 받아 변환하고 문서-어휘 행렬을 반환하는 함수
    '''

    X = cvect.fit_transform(corpus)
    print(cvect.get_feature_names_out())  # 어휘사전 출력
    dtm = X.toarray()
    df_dtm = pd.DataFrame(dtm, columns = cvect.get_feature_names_out())
    return df_dtm


df_dtm_content = display_transform_dtm(cvect_content, corpus_content)


type(df_dtm_content)


dtm_top_30_dict = dict(df_dtm_content.sum().sort_values(ascending=False).head(30))


dtm_top_30_dict


word_cloud = WordCloud(font_path=r'C:\Windows\Fonts\malgun.ttf',
                       width=800,
                       height=400,
                       background_color='white',
                       min_word_length = 2,
                       random_state=2024)
word_cloud.generate_from_frequencies(dtm_top_30_dict)
plt.imshow(word_cloud)
plt.show()


from konlpy.tag import Okt
okt = Okt()


from tqdm import tqdm
tqdm.pandas()


df['내용_명사'] = df['내용'].progress_map(lambda x : ' '.join(okt.nouns(x)))


corpus_content_nouns = df['내용_명사']
corpus_content_nouns


cvect_content_nouns = CountVectorizer(max_df=5,min_df=2, ngram_range=(1,2))


X_content_nouns = cvect_content_nouns.fit_transform(corpus_content_nouns)
X_content_nouns


df_dtm_content_nouns = display_transform_dtm(cvect_content_nouns, corpus_content_nouns)


df_dtm_content_nouns


dtm_nouns_top_30_dict = dict(df_dtm_content_nouns.sum().sort_values(ascending=False).head(30))


dtm_nouns_top_30_dict


# 오늘자 기사 
word_cloud = WordCloud(font_path=r'C:\Windows\Fonts\malgun.ttf',
                       width=800,
                       height=400,
                       background_color='white',
                       min_word_length = 2,
                       random_state=2024)
word_cloud.generate_from_frequencies(dtm_nouns_top_30_dict)
plt.imshow(word_cloud)
plt.show()


tfidfvect = TfidfVectorizer()
X_tfidf_content = tfidfvect.fit_transform(corpus_content)


dtm_tfidf_content = X_tfidf_content.toarray()


df_dtm_tfidf_content= display_transform_dtm(tfidfvect, corpus_content)


df_dtm_tfidf_content


df_dtm_tfidf_content_top_30_dict = dict(df_dtm_tfidf_content.sum().sort_values(ascending=False).head(30))


df_dtm_tfidf_content_top_30_dict


word_cloud = WordCloud(font_path=r'C:\Windows\Fonts\malgun.ttf',
                       width=800,
                       height=400,
                       background_color='white',
                       min_word_length = 2,
                       random_state=2024)
word_cloud.generate_from_frequencies(df_dtm_tfidf_content_top_30_dict)
plt.imshow(word_cloud)
plt.show()


vocab = tfidfvect.get_feature_names_out()
idf_dict = dict(zip(vocab, tfidfvect.idf_))
idf_dict


idf_dict.head(30)
